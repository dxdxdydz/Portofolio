{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **LIBRARY**\n* numpy :  1.18.5\n* pandas :  1.1.4\n* scikit-learn :  0.23.2\n* tensorflow :  2.3.1\n* nltk :  3.2.4\n* matplotlib :  3.2.1\n* PIL :  3.2.4","metadata":{}},{"cell_type":"code","source":"import sys\nimport numpy as np\nimport pandas as pd\nimport datetime\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow.keras.layers as layers\nfrom tensorflow import keras\n\nimport nltk\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"python : \", sys.version)\nprint(\"numpy : \", np.__version__)\nprint(\"pandas : \", pd.__version__)\nprint(\"scikit-learn : \", sklearn.__version__)\nprint(\"tensorflow : \", tf.__version__)\nprint(\"PIL : \", nltk.__version__)\nprint(\"nltk : \", nltk.__version__)\nprint(\"matplotlib : \", mpl.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_height, image_width = 80, 80\ndef get_image(dirpath, filepath):\n    \"\"\"\n        parameter: filepath, ex: image.jpg\n    \"\"\"\n    filedir =  dirpath + filepath\n    filename, filetype = filepath.split(\".\")\n    img = Image.open(filedir)\n    img = img.resize((image_width,image_height), Image.ANTIALIAS)\n    return np.asarray(img).astype('float32') / 250.0\n#     image = tf.io.read_file(filedir)\n#     if image is not None:\n#         if filetype == \"jpg\":\n#             image = tf.io.decode_jpeg(image)\n#         elif filetype == \"png\":\n#             image = tf.io.decode_png(image) \n#         image = tf.image.resize_with_crop_or_pad(image, 300, 300)\n#         image = tf.image.convert_image_dtype(image, dtype=tf.float32, saturate=False)       \n#     else:\n#         print(\"read_file is null\")\n#         return []\n    #return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data_url_csv = r\"../input/idndsc2020-shopee-advanced/new_training_set.csv\"\ntraining_image_dir = r\"../input/idndsc2020-shopee-advanced/training_img/training_img/\"\ntest_data_url_csv = r\"../input/idndsc2020-shopee-advanced/new_test_sample.csv\"\ntest_image_dir = r\"../input/idndsc2020-shopee-advanced/sample_img/sample_img/\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_raw = pd.read_csv(training_data_url_csv)\ndf_train_raw.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_raw.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_raw = pd.read_csv(test_data_url_csv)\ndf_test_raw.rename(columns={\"Unnamed: 0\": \"pair_index\"}, inplace=True)\ndf_test_raw.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_copy = df_train_raw.copy()\ndf_copy[\"filetype_1\"] = df_copy[\"image_1\"].map(lambda x: x.split('.')[1])\n\ndf_copy[\"filetype_2\"] = df_copy[\"image_2\"].map(lambda x: x.split('.')[1])\ndf_copy[\"filetype_2\"].value_counts()\n\nprint(\"File type image - 1 :\")\nprint(df_copy[\"filetype_1\"].value_counts())\nprint()\nprint(\"File type image - 2 :\")\nprint(df_copy[\"filetype_2\"].value_counts())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename_image1_unique = df_train_raw[\"image_1\"].values\nfilename_image2_unique = df_train_raw[\"image_2\"].values\nfilename_unique = np.concatenate((filename_image1_unique, filename_image2_unique))\nfilename_unique = set(filename_unique)\nfilename_unique = list(filename_unique)\n\nprint(\"Total file unique image - 1 : \", df_train_raw[\"image_1\"].unique().shape)\nprint(\"Total file unique image - 2 : \", df_train_raw[\"image_2\"].unique().shape)\nprint(\"Total file unique image 1 & 2 : \", len(filename_unique))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_train_unique = {}\nimages_test_unique = {}\nprint(\"start @@ \", datetime.datetime.now())\n\narr_space = np.linspace(0, len(filename_unique), 10)\nfor i, x  in enumerate(arr_space[:3]):\n    start = int(arr_space[i-1])\n    end = int(arr_space[i])\n    print(\"start : \", start, \" @@ end : \", end)\n    if i > 0 and i < len(arr_space):\n        temp_dict = {x: get_image(training_image_dir, x) for x in filename_unique[start:end]}\n        images_train_unique = dict(**images_train_unique, **temp_dict)\n\nprint(\"Count : \", len(images_train_unique))\nprint(\"finish @@ \", datetime.datetime.now())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"start @@ \", datetime.datetime.now())\n\nfor i, x  in enumerate(arr_space[3:6]):\n    i += 3\n    start = int(arr_space[i-1])\n    end = int(arr_space[i])\n    print(\"start : \", start, \" @@ end : \", end)\n    if i > 0 and i < len(arr_space):\n        temp_dict = {x: get_image(training_image_dir, x) for x in filename_unique[start:end]}\n        images_train_unique = dict(**images_train_unique, **temp_dict)\n\nprint(\"Count : \", len(images_train_unique))\nprint(\"finish @@ \", datetime.datetime.now())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"start @@ \", datetime.datetime.now())\n\nfor i, x  in enumerate(arr_space[6:8]):\n    i += 6\n    start = int(arr_space[i-1])\n    end = int(arr_space[i])\n    print(\"start : \", start, \" @@ end : \", end)\n    if i > 0 and i < len(arr_space):\n        temp_dict = {x: get_image(training_image_dir, x) for x in filename_unique[start:end]}\n        images_train_unique = dict(**images_train_unique, **temp_dict)\n\nprint(\"Count : \", len(images_train_unique))\nprint(\"finish @@ \", datetime.datetime.now())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"start @@ \", datetime.datetime.now())\n\nfor i, x  in enumerate(arr_space[8:10]):\n    i += 8\n    start = int(arr_space[i-1])\n    end = int(arr_space[i])\n    print(\"start : \", start, \" @@ end : \", end)\n    if i > 0 and i < len(arr_space):\n        temp_dict = {x: get_image(training_image_dir, x) for x in filename_unique[start:end]}\n        images_train_unique = dict(**images_train_unique, **temp_dict)\n\nprint(\"Count : \", len(images_train_unique))\nprint(\"finish @@ \", datetime.datetime.now())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image_from_memory(dirpath, key):\n    images_unique = {}\n    images_unique = images_test_unique if 'sample' in dirpath.split('/')[-2] else images_train_unique\n    if key in images_unique:\n        return images_unique[key][...,:3]\n    else:\n        new_image = get_image(dirpath, key)\n        images_unique[key] = new_image\n        return new_image[...,:3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_raw = df_train_raw[[\"image_1\", \"image_2\"]].values\ny = df_train_raw[\"Label\"].values\n\nX_train_raw, X_test_raw, y_train, y_test = train_test_split(X_raw, y, test_size = 0.25, random_state = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_image_1 = X_train_raw.T[0]\nX_train_image_2 = X_train_raw.T[1]\n\nX_train_image_1 = np.array([get_image_from_memory(training_image_dir, x) for x in X_train_image_1.tolist()])\nX_train_image_2 = np.array([get_image_from_memory(training_image_dir, x) for x in X_train_image_2.tolist()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_image_1 = X_test_raw.T[0]\nX_test_image_2 = X_test_raw.T[1]\n\nX_test_image_1 = np.array([get_image_from_memory(training_image_dir, x) for x in X_test_image_1.tolist()])\nX_test_image_2 = np.array([get_image_from_memory(training_image_dir, x) for x in X_test_image_2.tolist()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_sample_raw = df_test_raw[[\"image_1\", \"image_2\"]].values\nX_sample_image_1 = X_sample_raw.T[0]\nX_sample_image_2 = X_sample_raw.T[1]\n\nX_sample_image_1 = np.array([get_image_from_memory(test_image_dir, x) for x in X_sample_image_1.tolist()])\nX_sample_image_2 = np.array([get_image_from_memory(test_image_dir, x) for x in X_sample_image_2.tolist()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input_shape = (image_height,image_width,3)\n# def create_image_layer(input):\n#     layer = layers.Conv2D(64, kernel_size=5, padding='same', input_shape=input_shape)(input)\n#     layer = layers.MaxPool2D()(layer)\n    \n#     layer = layers.Conv2D(64, kernel_size=5, padding='same')(layer)\n#     layer = layers.MaxPool2D()(layer)\n#     layer = layers.Conv2D(64, kernel_size=5, padding='same')(layer)\n#     layer = layers.MaxPool2D()(layer)\n#     return layer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image1_input = keras.Input(shape=input_shape)\n# image1_layer = create_image_layer(image1_input)\n\n# image2_input = keras.Input(shape=input_shape)\n# image2_layer = create_image_layer(image2_input)\n\n# image_concate = layers.Concatenate()([image1_layer, image2_layer])\n# image_concate = layers.Flatten()(image_concate)\n\n# relu_1 = layers.Dense(32, activation='relu')(image_concate)\n\n# output = layers.Dense(1, activation='sigmoid')(relu_1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = keras.Model(inputs=[image1_input, image2_input], outputs=output)\n# model.compile(\n#     optimizer=\"adam\",\n#     loss=\"binary_crossentropy\",\n#     metrics=[\"binary_accuracy\"]\n# )\n# model.summary()\n# keras.utils.plot_model(model, \"test_model.png\", show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.fit(\n#     [X_train_image_1, X_train_image_2], \n#     y_train,\n#     batch_size=32,\n#     epochs=5\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_c=np.array([[X_train_image_1[n],X_train_image_2[n]] for n in range (len(X_train_image_1))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_c=np.array([[X_test_image_1[n],X_test_image_2[n]] for n in range (len(X_test_image_1))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_c.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_sample_c=np.array([[X_sample_image_1[n],X_sample_image_2[n]] for n in range (len(X_sample_image_1))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\nfrom keras.layers import Activation\nfrom keras.layers import Input, Lambda, Dense, Dropout, Convolution2D, MaxPooling2D, Flatten\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import RMSprop,Adam\nfrom keras import optimizers\nfrom keras import callbacks\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom keras.models import Model,load_model\nfrom keras.models import model_from_json, load_model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"left_input = Input(X_train_c.shape[2:])\nright_input = Input(X_train_c.shape[2:])\n\n# We will use 2 instances of 1 network for this task\nconvnet = Sequential([\n    Conv2D(8,(3,3), input_shape=X_train_c.shape[2:]),\n    Activation('relu'),\n    MaxPooling2D(),\n    Conv2D(8,(3,3)),\n    Activation('relu'),\n    MaxPooling2D(),\n    Conv2D(16,(3,3)),\n    Activation('relu'),\n    MaxPooling2D(),\n    Conv2D(16,(3,3)),\n    Activation('relu'),\n    Flatten(),\n    Dense(32),\n    Activation('sigmoid')\n])\n# Connect each 'leg' of the network to each input\n# Remember, they have the same weights\nencoded_l = convnet(left_input)\nencoded_r = convnet(right_input)\n\n# Getting the L1 Distance between the 2 encodings\nL1_layer = Lambda(lambda tensor:K.abs(tensor[0] - tensor[1]))\n\n# Add the distance function to the network\nL1_distance = L1_layer([encoded_l, encoded_r])\n\nprediction = Dense(1,activation='sigmoid')(L1_distance)\nsiamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n\noptimizer = Adam(0.0001, decay=2.5e-4)\n#//TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\nsiamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"siamese_net.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_1 = X_train_c[:, 0]\nimg_2 = X_train_c[:, 1]\nimgt_1 = X_test_c[:, 0]\nimgt_2 = X_test_c[:, 1]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsiamese_net.fit([img_1,img_2], y_train,\n          batch_size=16,\n          epochs=4,\n          verbose=1,\n          validation_data=([imgt_1,imgt_2],y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img_1 = tf.cast(img_1, dtype='float64')\n# img_2 = tf.cast(img_2, dtype='float64')\n# y_train = tf.cast(y_train, dtype='float64')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgc_1 = X_sample_c[:, 0]\nimgc_2 = X_sample_c[:, 1]\ny_prob=siamese_net.predict([imgc_1,imgc_2])\ny_prob","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('Display.max_rows',None)\npd.DataFrame(y_prob)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_prob[y_prob>0.5]=1\ny_prob[y_prob<0.5]=0\n\npd.DataFrame(y_prob).astype(int).to_csv('abc.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n=35\nfig, axs = plt.subplots()\nplt.imshow(imgc_1[n])\nfig, axs = plt.subplots()\nplt.imshow(imgc_2[n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}